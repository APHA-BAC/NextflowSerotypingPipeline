1) Installing and running Nextflow:
- create a new directory (e.g. called nextflow) in your /home directory (e.g. /home/jaromirguzinski/nextflow - where jaromirguzinski can be replaced by the general designation $USER whenever you specify a path to this directory)
- cd into /nextflow and follow the instructions here https://www.nextflow.io/ (Nextflow homepage)
- copy the command curl -s https://get.nextflow.io | bash from the Nextflow homepage and paste it into the terminal
- the script should only need less than a minute to run, and when finished a shell script file called nextflow will appear in the /nextflow directory
- test if the Nextflow installation has completed without any errors by pasting the ./nextflow run hello command into the terminal

- it is recommended to keep the Nextflow script files (Nextflow serotyping pipeline script with the extension .nf) in the same directory as the nextflow shell script
- thus if the Nextflow script file is for example called pipeline.nf, this can be launched from the /home/jaromirguzinski/nextflow directory using the ./nextflow run pipeline_disk.nf command
- after launching the Nextflow script, a new directory called "work" will appear in /home/$USER/nextflow
- /home/$USER/nextflow/work will be continously updated while the Nextflow script is running and some output files as well as temporary files will be saved there

- in this repo there are four versions of the Nextflow serotyping pipeline script: SCE2_pipeline.nf, SCE2_pipeline_disk.nf, SCE3_pipeline, SCE3_pipeline_disk.nf
- the SCE scripts are compatible with the SCEv2 computing environment, and the SCE3 scripts are compatible with the SCEv3 computing environment
- the main difference is in the paths directing the pipeline to the various pipeline component software
- the scripts labelled with "_disk" should be utilised when the input and the output data are stored on an external hard disk
- whereas if the input and the output data are stored directly in the /home/$USER directory (which may only be suitable for smaller amounts of data due to potential space restrictions in the /home/$USER directory), the SCE2_pipeline.nf and SCE3_pipeline.nf scripts should be used

2) Installing pipeline component software
- FastQC (https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)
Download the zip file from here: http://www.bioinformatics.babraham.ac.uk/projects/download.html#fastqc and follow the instructions: https://raw.githubusercontent.com/s-andrews/FastQC/master/INSTALL.txt to install
If the install has been performed correctly, the "fastqc" command will be sufficient to launch this Nextflow serotyping pipeline process 

- shovill (https://github.com/tseemann/shovill)
Use conda to install shovill and all dependencies: conda install -c conda-forge -c bioconda -c defaults shovill
If the install has been performed correctly, the "shovill" command will be sufficient to launch this Nextflow serotyping pipeline process 

- quast (http://quast.sourceforge.net/quast.html)
Seems it is easiest to download quast by using the command: tar -xzf quast-<VERSION>.tar.gz
Download and then unpack the tar.gz file into a directory in your /home, for example: /home/$USER/quast-5.0.2 
To launch this Nextflow serotyping pipeline process, use the command: python /home/$USER/quast-5.0.2/quast.py to specify the path to the quast.py Python file 

- KmerID (https://github.com/phe-bioinformatics/kmerid)
Unpack the tar.gz archive that was downloaded into a newly created directory in your /home (for example: /home/$USER/kmerid)
Compile the auxilliary executables by typing "make all" when in the /home/$USER/kmerid directory
Replace the Python 2 compatible kmerid.py file that came with the original installation with the edited Python 3 compatible kmerid_python3.py file (in this repo in the "pipeline component Python 3 scripts/KmerID" folder)
Important: open the kmerid_python3.py file and if necessary edit the lines of code with the text intersect_kmer_lists_filelist (line 97, line 144, line 195) and kmer_reads_process_stdin (line 82), and make sure that there is specified the full path to the /bin directory where these files are located (thus for example: "/home/$USER/kmerid/bin/intersect_kmer_lists_filelist")
Check that the KmerID reference genome files correspond to the bacterial genera against which the analysed samples ought to be compared, and edit the /home/$USER/kmerid/config/config.cnf file as needed 
To launch this Nextflow serotyping pipeline process, use the command: python /home/$USER/kmerid/kmerid_python3.py to specify the path to the kmerid_python3.py Python file 

- MOST (https://github.com/phe-bioinformatics/MOST)
For MOST to function in a Python 3 set-up, all of the Python files that come with the original release of MOST need to be replaced with the Python 3 version of these files that can be found in this repo in the "pipeline component Python 3 scripts/MOST" folder
The MOST.py is the master script file and the remaining scripts are not accessed directly but through the MOST.py script
Important: therefore in the directory structure the MOST.py script needs to be placed in a directory above the support script files, and the support script files need to be placed in a directory called "modules" 
Thus if MOST.py is in the /home/$USER/most/MOST-master directory, the other Python scripts need to be placed in the /home/$USER/most/MOST-master/modules directory 
Apart from the Python scripts, there will also be a need to install bowtie 2-2.1.0 (example of a path to software: /home/$USER/most/bowtie2-2.1.0/bowtie2), samtools 0.1.18 (example of a path to software: /opt/samtools-0.1.18/samtools), and the Salmomella MLST database (/home/$USER/most/MOST-master/MLST_data/salmonella) 
To launch this Nextflow serotyping pipeline process, use the command: python /home/$USER/most/MOST-master/MOST.py to specify the path to the MOST.py Python file 

- SeqSero2 (https://github.com/denglab/SeqSero2) 
Use conda to install the software: conda install -c bioconda seqsero2=1.1.1
To launch this Nextflow serotyping pipeline process, use the command: SeqSero2_package.py 

- sistr (https://github.com/phac-nml/sistr_cmd)
Use conda to install the software, first the necessary channels:
conda config --add channels conda-forge
conda config --add channels defaults
conda config --add channels r
conda config --add channels bioconda
And then sistr:
conda install sistr_cmd
It may be necessary to update the versions of numpy and pandas for sistr to function:
pip install --upgrade pip
pip install wheel
pip install numpy pandas
To launch this Nextflow serotyping pipeline process, use the command: sistr

- srst2 (https://github.com/katholt/srst2) 
To install, clone the git repository: git clone https://github.com/katholt/srst2
Then install with pip: pip install srst2/
Important: it is necessary to replace the Python 2 compatible srst2.py script that comes with the original distribution with the edited Python 3 compatible srst2.py script that can be found in this repo in the "pipeline component Python 3 scripts/srst2" folder 
Example of a path to the srst2.py script: /home/$USER/srst2/scripts/srst2.py
The path to the vaccine differentiation database needs to be specified, for example: /home/$USER/srst2/VaccineDifferentiation/allVacDB9d_clustered.fasta
It is necessary to have bowtie (for example bowtie2-2.2.3) installed and to specify the path as follows prior to running srst2:
export SRST2_BOWTIE2=/home/$USER/srst2/bowtie2-2.2.3/bowtie2
export SRST2_BOWTIE2_BUILD=/home/$USER/srst2/bowtie2-2.2.3/bowtie2-build
To launch this Nextflow serotyping pipeline process, use the command: srst2

3) Instructions for running the Nextflow serotyping pipeline in SCEv3
- the assumption is that the R1 and R2 fastq files for all of the isolates to be serotyped will be stored during the pipeline run on an external hard disk that will be mounted onto a directory called /disk
- thus the path to access the external hard disk will be /home/$USER/disk 
- after entering the /home/$USER/disk directory, two directories need to be created there: /WGS_Data and /WGS_Results
- additionally, in the /WGS_Data directory it will be necesseary to create a directory named (for example) after the sequencing run to be analysed: for example /home/$USER/disk/WGS_Data/run_n900  
- the /WGS_Data/sequencing_run_name directory must contain the R1 and R2 fastq files for all isolates to be analysed in the Nextflow pipeline run 
- the /WGS_Results is a directory where the serotyping pipeline output files will be written out to: /home/$USER/disk/WGS_Results
- prior to launching the Nextlow pipeline script it needs to be made sure that there is sequencing data in the /home/$USER/WGS_Data/sequencing_run_name directory, that the /home/$USER/disk/WGS_Results directory is empty, and the previous run's /work directory has been deleted from /home/$USER/nextflow 
- cd into the /home/$USER/nextflow directory and launch the Nextflow pipeline script (in this scenario use: ./nextflow run SCE3_pipeline_disk.nf)
- several seconds will pass while the script is launching and the message "Please enter the name of directory where the sequences are located:" will appear in the terminal
- after the appearance of the message use the keyboard to enter the sequencing_run_name on the same line as the message in the terminal, i.e. this has to completely match the name of directory where the fastq files are stored in /home/$USER/WGS_Data 
- the Nextflow serotyping pipeline will start running and all the pipeline component software processes will be 100% finalized upon the successful completetion of the pipeline 

4) Instructions for running the Nextflow serotyping pipeline in SCEv2
- same as for running the Nextflow pipeline in SCEv3 but it is important to be sure that all paths are edited/updated if needed - thus use the provided "SCE2_" .nf scripts
- in particular, if the data are to be read from and written out to /WGS_Data and /WGS_Results, respectively, on the /home directory rather than from an external hard disk, the paths in the .nf script will need to be updated to reflect this (use the ./nextflow run SCE2_pipeline.nf to launch the pipeline under this scenario)  

5) Summary table
- the summaryTable_Python3.py scipt gathers the data from the output directories for each of the serotyped isolates and collates that data into a single summary table 
- depending on whether the pipeline input and output data are located in the /home directory or on the external hard disk (/disk), there is a need to edit line 101 of the summaryTable_Python3.py script
- line 101 is: pathoData = glob.glob("/home/*/disk/WGS_Data/*"), either with (data stored on /disk) or without (data stored in /home) "/disk"
- the summaryTable_Python3.py (copied from this repo) has to be stored in a directory called "summary", thus the full path will be: /home/$USER/summary/summaryTable_Python3.py
- to launch this script as part of the Nextflow pipeline use: python /home/$USER/summary/summaryTable_Python3.py
